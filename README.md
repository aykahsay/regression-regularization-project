# Regression Regularization Project

## ğŸ“Œ Objective
The purpose of this project is to explore **regularization** and **dimension-reduction** techniques in regression analysis.  
Specifically, it compares **Ridge Regression**, **Lasso Regression**, and **Partial Least Squares (PLS)** regression in terms of their ability to handle multicollinearity, perform feature selection, and improve predictive performance.

---

## ğŸ“š Contents
- `data/` â€“ dataset (or link to source) and dataset description  
- `R/` â€“ R scripts for data preprocessing, model fitting, and helper functions  
- `report/` â€“ final RMarkdown report (max 10 pages)  
- `docs/` â€“ generated figures and tables  
- `outputs/` â€“ model outputs and saved results  

---

## ğŸ“Š Dataset
- **Source:** [Insert dataset link or package name here]  
- **Response Variable (Y):** Continuous outcome variable  
- **Predictors (X):** â‰¥10 predictors (continuous and/or categorical)  
- **Sample Size:** [Insert sample size here]  
- **Reason for Selection:** The dataset includes multiple predictors and potential multicollinearity, making it suitable for demonstrating Ridge, Lasso, and PLS regression.

---

## âš™ï¸ Methods
1. **Ridge Regression** â€“ adds L2 penalty to shrink coefficients and handle multicollinearity.  
2. **Lasso Regression** â€“ adds L1 penalty, shrinking some coefficients to zero (feature selection).  
3. **Partial Least Squares (PLS)** â€“ projects predictors into latent components while considering the response.  

---

## ğŸ“ˆ Deliverables
- **Report:** Includes introduction, methodology, results, discussion, and references (â‰¤10 pages).  
- **Code:** All R scripts (`.R`) or RMarkdown (`.Rmd`) files.  
- **Dataset:** Either uploaded or linked if publicly available.  

---

## â–¶ï¸ How to Run
1. Clone the repository:
   ```bash
   git clone https://github.com/aykahsay/regression-regularization-project.git
   cd regression-regularization-project
